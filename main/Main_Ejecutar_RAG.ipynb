{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "print(\"Desinstalando torch, torchvision, torchaudio, bitsandbytes...\")\n",
        "!pip uninstall torch torchvision torchaudio bitsandbytes -y\n",
        "\n",
        "print(\"Limpiando la caché de pip...\")\n",
        "!pip cache purge\n",
        "\n",
        "print(\"Verificando la versión de CUDA...\")\n",
        "!nvcc --version\n",
        "\n",
        "print(\"Instalando PyTorch para la versión correcta de CUDA...\")\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
        "\n",
        "print(\"Instalando bitsandbytes de forma robusta...\")\n",
        "!pip install bitsandbytes==0.41.3 --prefer-binary\n",
        "\n",
        "print(\"Instalando/actualizando transformers, accelerate, langchain y streamlit...\")\n",
        "!pip install -U transformers accelerate langchain langchain-community langchain-huggingface streamlit chromadb sentence-transformers\n",
        "\n",
        "print(\"Todas las librerías instaladas. Reiniciando el entorno de ejecución para aplicar cambios...\")\n",
        "import os\n",
        "os.kill(os.getpid(), 9)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zhlosQFjDSEe",
        "outputId": "f6d7b6a9-2f25-4aa6-da8b-5cbfaeb8ee69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Desinstalando torch, torchvision, torchaudio, bitsandbytes...\n",
            "Found existing installation: torch 2.5.1+cu121\n",
            "Uninstalling torch-2.5.1+cu121:\n",
            "  Successfully uninstalled torch-2.5.1+cu121\n",
            "Found existing installation: torchvision 0.20.1+cu121\n",
            "Uninstalling torchvision-0.20.1+cu121:\n",
            "  Successfully uninstalled torchvision-0.20.1+cu121\n",
            "Found existing installation: torchaudio 2.5.1+cu121\n",
            "Uninstalling torchaudio-2.5.1+cu121:\n",
            "  Successfully uninstalled torchaudio-2.5.1+cu121\n",
            "Found existing installation: bitsandbytes 0.41.3\n",
            "Uninstalling bitsandbytes-0.41.3:\n",
            "  Successfully uninstalled bitsandbytes-0.41.3\n",
            "Limpiando la caché de pip...\n",
            "Files removed: 28\n",
            "Verificando la versión de CUDA...\n",
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2024 NVIDIA Corporation\n",
            "Built on Thu_Jun__6_02:18:23_PDT_2024\n",
            "Cuda compilation tools, release 12.5, V12.5.82\n",
            "Build cuda_12.5.r12.5/compiler.34385749_0\n",
            "Instalando PyTorch para la versión correcta de CUDA...\n",
            "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
            "Collecting torch\n",
            "  Downloading https://download.pytorch.org/whl/cu121/torch-2.5.1%2Bcu121-cp311-cp311-linux_x86_64.whl (780.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m780.5/780.5 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision\n",
            "  Downloading https://download.pytorch.org/whl/cu121/torchvision-0.20.1%2Bcu121-cp311-cp311-linux_x86_64.whl (7.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.3/7.3 MB\u001b[0m \u001b[31m114.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchaudio\n",
            "  Downloading https://download.pytorch.org/whl/cu121/torchaudio-2.5.1%2Bcu121-cp311-cp311-linux_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m97.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.5.82)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Installing collected packages: torch, torchvision, torchaudio\n",
            "Successfully installed torch-2.5.1+cu121 torchaudio-2.5.1+cu121 torchvision-0.20.1+cu121\n",
            "Instalando bitsandbytes de forma robusta...\n",
            "Collecting bitsandbytes==0.41.3\n",
            "  Downloading bitsandbytes-0.41.3-py3-none-any.whl.metadata (9.8 kB)\n",
            "Downloading bitsandbytes-0.41.3-py3-none-any.whl (92.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.6/92.6 MB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: bitsandbytes\n",
            "Successfully installed bitsandbytes-0.41.3\n",
            "Instalando/actualizando transformers, accelerate, langchain y streamlit...\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.53.0)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.8.1)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.26)\n",
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.11/dist-packages (0.3.26)\n",
            "Requirement already satisfied: langchain-huggingface in /usr/local/lib/python3.11/dist-packages (0.3.0)\n",
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.11/dist-packages (1.46.1)\n",
            "Requirement already satisfied: chromadb in /usr/local/lib/python3.11/dist-packages (1.0.13)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (4.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.5.1+cu121)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.66 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.66)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.4.1)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.7)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.41)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (8.5.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.10.1)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.4.1)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.2.1)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.2.1)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.14.0)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.2.2.post1)\n",
            "Requirement already satisfied: pybase64>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.4.1)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.34.3)\n",
            "Requirement already satisfied: posthog>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.0.0)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.22.0)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.34.1)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.34.1)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.34.1)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.48.9)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.73.0)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.3.0)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.16.0)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (33.1.0)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (5.1.0)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb) (3.10.18)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (13.9.4)\n",
            "Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.24.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.15.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.44.0)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (2025.6.15)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.16.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (0.25.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.38.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (3.3.1)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.4.0)\n",
            "Requirement already satisfied: durationpy>=0.7 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (0.10)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (1.33)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.7.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.70.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.34.1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.34.1)\n",
            "Requirement already satisfied: opentelemetry-proto==1.34.1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.34.1)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.55b1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-sdk>=1.2.0->chromadb) (0.55b1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
            "Requirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb) (1.9.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.1.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (2.19.2)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.0.0->accelerate) (12.5.82)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.4)\n",
            "Requirement already satisfied: uvloop>=0.15.1 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.1.0)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9.1)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.23.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain) (3.0.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.1.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.11/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FvgTd9gC7ro-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b198ee7-9a61-42c5-b6e2-0cde516cb56f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34.55.110.29\n"
          ]
        }
      ],
      "source": [
        "!wget -q -O - ipv4.icanhazip.com"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip  install -q streamlit"
      ],
      "metadata": {
        "id": "6cPJN6ES7yfm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install rouge-score"
      ],
      "metadata": {
        "id": "ZexF-FRR70y8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50e0c1c3-d3fa-49bc-c559-5aec6db27b99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "# Librerías base de LangChain y gestión de documentos\n",
        "!pip install -q langchain chromadb langchain-community pypdf\n",
        "\n",
        "# Actualización y soporte para integración con Hugging Face\n",
        "!pip install -q --upgrade langchain\n",
        "!pip install -q transformers accelerate huggingface-hub\n",
        "!pip install -U langchain-huggingface\n",
        "\n",
        "\n",
        "# Paquete adicional para embeddings y soporte multimodal\n",
        "!pip install -q -U langchain-community langchain sentence-transformers transformers\n",
        "\n",
        "# stremlit\n",
        "!pip install streamlit"
      ],
      "metadata": {
        "id": "tymHaR4O75cV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LangChain y procesamiento de documentos\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.llms import HuggingFaceHub\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.schema import Document\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.chains import RetrievalQAWithSourcesChain\n",
        "from langchain.docstore.document import Document\n",
        "from langchain.text_splitter import MarkdownHeaderTextSplitter\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline, BitsAndBytesConfig\n",
        "from langchain_huggingface import HuggingFacePipeline\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "# Utilidades\n",
        "import os\n",
        "import shutil\n",
        "import re\n",
        "\n",
        "# Autentificación HugginFace\n",
        "from huggingface_hub import login\n",
        "\n",
        "# Uso de Key\n",
        "from google.colab import userdata\n",
        "\n",
        "# streamlit\n",
        "import streamlit as st\n",
        "from functools import lru_cache"
      ],
      "metadata": {
        "id": "xmi76WJO78Mh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive"
      ],
      "metadata": {
        "id": "dbJqpduE8A_Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "id": "ufBRPvca8C6c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d8d870f-6e3a-46a2-edb8-0d78e17b05ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run modulo_cargue_documentos_RAG.py & npx localtunnel --port 8501"
      ],
      "metadata": {
        "id": "MWzWhYSZ741q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b034c279-c7e7-4359-c721-a8851e401304"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.55.110.29:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K\u001b[1G\u001b[0JNeed to install the following packages:\n",
            "localtunnel@2.0.2\n",
            "Ok to proceed? (y) \u001b[20Gy\n",
            "\n",
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0Kyour url is: https://true-donkeys-serve.loca.lt\n",
            "2025-06-29 00:36:10.058722: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1751157370.082688    9425 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1751157370.090062    9425 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "/content/Rag_answert_Poli_con_selector_modulo_visible.py:76: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
            "  return HuggingFaceEmbeddings(\n",
            "modules.json: 100% 349/349 [00:00<00:00, 2.37MB/s]\n",
            "config_sentence_transformers.json: 100% 116/116 [00:00<00:00, 893kB/s]\n",
            "README.md: 10.5kB [00:00, 35.0MB/s]\n",
            "sentence_bert_config.json: 100% 53.0/53.0 [00:00<00:00, 456kB/s]\n",
            "config.json: 100% 612/612 [00:00<00:00, 5.85MB/s]\n",
            "model.safetensors: 100% 90.9M/90.9M [00:00<00:00, 99.7MB/s]\n",
            "tokenizer_config.json: 100% 350/350 [00:00<00:00, 3.07MB/s]\n",
            "vocab.txt: 232kB [00:00, 7.15MB/s]\n",
            "tokenizer.json: 466kB [00:00, 22.6MB/s]\n",
            "special_tokens_map.json: 100% 112/112 [00:00<00:00, 837kB/s]\n",
            "config.json: 100% 190/190 [00:00<00:00, 1.53MB/s]\n",
            "/content/Rag_answert_Poli_con_selector_modulo_visible.py:84: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
            "  return Chroma(\n",
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n",
            "🔄 Creando pipeline de generación de texto...\n",
            "🔄 Cargando tokenizer...\n",
            "tokenizer_config.json: 100% 54.5k/54.5k [00:00<00:00, 61.7MB/s]\n",
            "tokenizer.json: 100% 9.09M/9.09M [00:00<00:00, 22.9MB/s]\n",
            "special_tokens_map.json: 100% 296/296 [00:00<00:00, 2.89MB/s]\n",
            "✅ Tokenizer cargado.\n",
            "🔄 Cargando modelo...\n",
            "config.json: 100% 878/878 [00:00<00:00, 8.35MB/s]\n",
            "model.safetensors.index.json: 100% 20.9k/20.9k [00:00<00:00, 99.3MB/s]\n",
            "Fetching 2 files:   0% 0/2 [00:00<?, ?it/s]\n",
            "model-00002-of-00002.safetensors:   0% 0.00/1.46G [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   0% 0.00/4.97G [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:   0% 5.54M/1.46G [00:00<02:27, 9.83MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   3% 42.5M/1.46G [00:00<00:18, 77.6MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   0% 354k/4.97G [00:00<2:44:16, 504kB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:   6% 84.7M/1.46G [00:00<00:09, 138MB/s] \u001b[A\n",
            "model-00002-of-00002.safetensors:   8% 116M/1.46G [00:00<00:07, 175MB/s] \u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   0% 6.59M/4.97G [00:00<10:01, 8.25MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  10% 145M/1.46G [00:01<00:06, 202MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   0% 12.8M/4.97G [00:01<06:01, 13.7MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  12% 177M/1.46G [00:01<00:07, 174MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   1% 39.3M/4.97G [00:01<01:38, 50.2MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  18% 270M/1.46G [00:01<00:04, 293MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  21% 308M/1.46G [00:01<00:03, 312MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   2% 83.0M/4.97G [00:01<00:46, 106MB/s] \u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   3% 134M/4.97G [00:01<00:28, 169MB/s] \u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   3% 169M/4.97G [00:01<00:23, 202MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   5% 226M/4.97G [00:01<00:19, 238MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  24% 351M/1.46G [00:02<00:06, 180MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  26% 380M/1.46G [00:02<00:05, 182MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   5% 255M/4.97G [00:02<00:26, 180MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  30% 434M/1.46G [00:02<00:04, 227MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   8% 410M/4.97G [00:02<00:11, 397MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  10% 493M/4.97G [00:05<00:56, 79.9MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  34% 491M/1.46G [00:05<00:19, 49.3MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  12% 591M/4.97G [00:05<00:48, 90.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  14% 717M/4.97G [00:06<00:35, 121MB/s] \u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  38% 558M/1.46G [00:06<00:18, 49.2MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  16% 770M/4.97G [00:08<01:05, 63.7MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  42% 613M/1.46G [00:08<00:23, 36.0MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  18% 874M/4.97G [00:08<00:43, 94.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  19% 941M/4.97G [00:09<00:33, 120MB/s] \u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  43% 625M/1.46G [00:09<00:22, 36.5MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  22% 1.08G/4.97G [00:09<00:20, 191MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  23% 1.16G/4.97G [00:10<00:31, 121MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  47% 681M/1.46G [00:10<00:22, 35.1MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  50% 729M/1.46G [00:13<00:24, 30.0MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  26% 1.27G/4.97G [00:13<00:47, 77.9MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  55% 796M/1.46G [00:13<00:14, 44.5MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  28% 1.37G/4.97G [00:13<00:35, 101MB/s] \u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  28% 1.41G/4.97G [00:13<00:32, 109MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  59% 863M/1.46G [00:14<00:11, 50.5MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  30% 1.48G/4.97G [00:14<00:36, 95.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  31% 1.54G/4.97G [00:15<00:35, 95.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  32% 1.58G/4.97G [00:15<00:39, 85.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  32% 1.60G/4.97G [00:17<01:01, 54.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  35% 1.74G/4.97G [00:17<00:29, 111MB/s] \u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  36% 1.80G/4.97G [00:17<00:26, 119MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  61% 892M/1.46G [00:17<00:21, 26.6MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  66% 959M/1.46G [00:18<00:12, 38.9MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  38% 1.87G/4.97G [00:18<00:25, 123MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  39% 1.94G/4.97G [00:18<00:24, 122MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  40% 1.97G/4.97G [00:19<00:25, 115MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  40% 1.99G/4.97G [00:19<00:29, 102MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  41% 2.06G/4.97G [00:20<00:26, 110MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  69% 1.01G/1.46G [00:20<00:12, 35.3MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  43% 2.12G/4.97G [00:20<00:22, 124MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  44% 2.19G/4.97G [00:20<00:22, 125MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  45% 2.22G/4.97G [00:21<00:22, 120MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  46% 2.27G/4.97G [00:21<00:23, 113MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  47% 2.34G/4.97G [00:23<00:35, 74.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  48% 2.41G/4.97G [00:23<00:27, 92.9MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  74% 1.08G/1.46G [00:23<00:14, 26.8MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  49% 2.43G/4.97G [00:24<00:30, 81.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  51% 2.55G/4.97G [00:24<00:22, 106MB/s] \u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  53% 2.61G/4.97G [00:26<00:27, 85.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  54% 2.67G/4.97G [00:26<00:25, 90.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  55% 2.73G/4.97G [00:26<00:19, 115MB/s] \u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  57% 2.83G/4.97G [00:26<00:12, 172MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  60% 2.98G/4.97G [00:27<00:07, 279MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  62% 3.06G/4.97G [00:27<00:05, 336MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  64% 3.20G/4.97G [00:28<00:08, 201MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  78% 1.14G/1.46G [00:29<00:17, 18.2MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  65% 3.25G/4.97G [00:29<00:12, 135MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  67% 3.31G/4.97G [00:31<00:22, 72.7MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  82% 1.20G/1.46G [00:31<00:12, 20.5MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  68% 3.38G/4.97G [00:31<00:17, 92.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  69% 3.45G/4.97G [00:31<00:12, 119MB/s] \u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  70% 3.50G/4.97G [00:31<00:10, 142MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  87% 1.27G/1.46G [00:32<00:07, 26.7MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  72% 3.57G/4.97G [00:32<00:11, 125MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  73% 3.63G/4.97G [00:33<00:12, 110MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  74% 3.70G/4.97G [00:34<00:13, 94.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  76% 3.77G/4.97G [00:35<00:14, 80.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  77% 3.83G/4.97G [00:35<00:13, 87.1MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  92% 1.34G/1.46G [00:36<00:05, 23.6MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  78% 3.88G/4.97G [00:36<00:12, 88.8MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  95% 1.39G/1.46G [00:37<00:02, 26.0MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  79% 3.92G/4.97G [00:37<00:15, 67.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  80% 3.97G/4.97G [00:37<00:11, 88.0MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors: 100% 1.46G/1.46G [00:37<00:00, 38.6MB/s]\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  81% 4.04G/4.97G [00:38<00:09, 102MB/s] \u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  83% 4.11G/4.97G [00:38<00:07, 119MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  84% 4.17G/4.97G [00:38<00:05, 150MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  85% 4.24G/4.97G [00:38<00:04, 179MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  87% 4.31G/4.97G [00:39<00:03, 190MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  88% 4.37G/4.97G [00:39<00:02, 230MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  89% 4.44G/4.97G [00:39<00:02, 219MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  91% 4.51G/4.97G [00:40<00:02, 178MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  92% 4.58G/4.97G [00:40<00:02, 164MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  94% 4.64G/4.97G [00:41<00:02, 158MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors: 100% 4.97G/4.97G [00:41<00:00, 119MB/s]\n",
            "Fetching 2 files: 100% 2/2 [00:41<00:00, 20.94s/it]\n",
            "Loading checkpoint shards: 100% 2/2 [00:01<00:00,  1.01it/s]\n",
            "generation_config.json: 100% 189/189 [00:00<00:00, 1.67MB/s]\n",
            "✅ Modelo cargado.\n",
            "Device set to use cuda:0\n",
            "The model 'LlamaForCausalLM' is not supported for text2text-generation. Supported models are ['PeftModelForSeq2SeqLM', 'BartForConditionalGeneration', 'BigBirdPegasusForConditionalGeneration', 'BlenderbotForConditionalGeneration', 'BlenderbotSmallForConditionalGeneration', 'EncoderDecoderModel', 'FSMTForConditionalGeneration', 'GPTSanJapaneseForConditionalGeneration', 'GraniteSpeechForConditionalGeneration', 'LEDForConditionalGeneration', 'LongT5ForConditionalGeneration', 'M2M100ForConditionalGeneration', 'MarianMTModel', 'MBartForConditionalGeneration', 'MT5ForConditionalGeneration', 'MvpForConditionalGeneration', 'NllbMoeForConditionalGeneration', 'PegasusForConditionalGeneration', 'PegasusXForConditionalGeneration', 'PLBartForConditionalGeneration', 'ProphetNetForConditionalGeneration', 'Qwen2AudioForConditionalGeneration', 'SeamlessM4TForTextToText', 'SeamlessM4Tv2ForTextToText', 'SwitchTransformersForConditionalGeneration', 'T5ForConditionalGeneration', 'T5GemmaForConditionalGeneration', 'UMT5ForConditionalGeneration', 'XLMProphetNetForConditionalGeneration'].\n",
            "/content/Rag_answert_Poli_con_selector_modulo_visible.py:170: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
            "  qa_memory = ConversationBufferMemory(\n",
            "🔄 Creando pipeline de generación de texto...\n",
            "🔄 Cargando tokenizer...\n",
            "✅ Tokenizer cargado.\n",
            "🔄 Cargando modelo...\n",
            "Loading checkpoint shards: 100% 2/2 [00:02<00:00,  1.06s/it]\n",
            "✅ Modelo cargado.\n",
            "Device set to use cuda:0\n",
            "The model 'LlamaForCausalLM' is not supported for text2text-generation. Supported models are ['PeftModelForSeq2SeqLM', 'BartForConditionalGeneration', 'BigBirdPegasusForConditionalGeneration', 'BlenderbotForConditionalGeneration', 'BlenderbotSmallForConditionalGeneration', 'EncoderDecoderModel', 'FSMTForConditionalGeneration', 'GPTSanJapaneseForConditionalGeneration', 'GraniteSpeechForConditionalGeneration', 'LEDForConditionalGeneration', 'LongT5ForConditionalGeneration', 'M2M100ForConditionalGeneration', 'MarianMTModel', 'MBartForConditionalGeneration', 'MT5ForConditionalGeneration', 'MvpForConditionalGeneration', 'NllbMoeForConditionalGeneration', 'PegasusForConditionalGeneration', 'PegasusXForConditionalGeneration', 'PLBartForConditionalGeneration', 'ProphetNetForConditionalGeneration', 'Qwen2AudioForConditionalGeneration', 'SeamlessM4TForTextToText', 'SeamlessM4Tv2ForTextToText', 'SwitchTransformersForConditionalGeneration', 'T5ForConditionalGeneration', 'T5GemmaForConditionalGeneration', 'UMT5ForConditionalGeneration', 'XLMProphetNetForConditionalGeneration'].\n",
            "🔄 Creando pipeline de generación de texto...\n",
            "🔄 Cargando tokenizer...\n",
            "✅ Tokenizer cargado.\n",
            "🔄 Cargando modelo...\n",
            "Loading checkpoint shards: 100% 2/2 [00:01<00:00,  1.05it/s]\n",
            "✅ Modelo cargado.\n",
            "Device set to use cuda:0\n",
            "The model 'LlamaForCausalLM' is not supported for text2text-generation. Supported models are ['PeftModelForSeq2SeqLM', 'BartForConditionalGeneration', 'BigBirdPegasusForConditionalGeneration', 'BlenderbotForConditionalGeneration', 'BlenderbotSmallForConditionalGeneration', 'EncoderDecoderModel', 'FSMTForConditionalGeneration', 'GPTSanJapaneseForConditionalGeneration', 'GraniteSpeechForConditionalGeneration', 'LEDForConditionalGeneration', 'LongT5ForConditionalGeneration', 'M2M100ForConditionalGeneration', 'MarianMTModel', 'MBartForConditionalGeneration', 'MT5ForConditionalGeneration', 'MvpForConditionalGeneration', 'NllbMoeForConditionalGeneration', 'PegasusForConditionalGeneration', 'PegasusXForConditionalGeneration', 'PLBartForConditionalGeneration', 'ProphetNetForConditionalGeneration', 'Qwen2AudioForConditionalGeneration', 'SeamlessM4TForTextToText', 'SeamlessM4Tv2ForTextToText', 'SwitchTransformersForConditionalGeneration', 'T5ForConditionalGeneration', 'T5GemmaForConditionalGeneration', 'UMT5ForConditionalGeneration', 'XLMProphetNetForConditionalGeneration'].\n",
            "/content/Rag_answert_Poli_con_selector_modulo_visible.py:262: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  respuesta = qa(query)\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionQueryEvent: capture() takes 1 positional argument but 3 were given\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\u001b[31m──\u001b[0m\u001b[31m────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m─────────────────────────\u001b[0m\u001b[31m──\u001b[0m\n",
            "\u001b[31m \u001b[0m \u001b[2;33m/usr/local/lib/python3.11/dist-packages/streamlit/runtime/scriptrunner/\u001b[0m\u001b[1;33mexec_code.py\u001b[0m: \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m \u001b[94m128\u001b[0m in \u001b[92mexec_func_with_error_handling\u001b[0m                                                 \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m \u001b[2;33m/usr/local/lib/python3.11/dist-packages/streamlit/runtime/scriptrunner/\u001b[0m\u001b[1;33mscript_runner\u001b[0m \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m \u001b[1;33m.py\u001b[0m:\u001b[94m669\u001b[0m in \u001b[92mcode_to_exec\u001b[0m                                                              \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m \u001b[2;33m/content/\u001b[0m\u001b[1;33mRag_answert_Poli_con_selector_modulo_visible.py\u001b[0m:\u001b[94m157\u001b[0m in \u001b[92m<module>\u001b[0m             \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m   \u001b[2m154 \u001b[0mstatus = st.empty()                                                            \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m   \u001b[2m155 \u001b[0mstatus.info(\u001b[33m\"\u001b[0m\u001b[33mCargando base vectorial y modelo de lenguaje...\u001b[0m\u001b[33m\"\u001b[0m)                 \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m   \u001b[2m156 \u001b[0m                                                                               \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m \u001b[31m❱ \u001b[0m157 vectordb = \u001b[1;4mget_vectordb()\u001b[0m                                                      \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m   \u001b[2m158 \u001b[0mretriever = vectordb.as_retriever(                                             \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m   \u001b[2m159 \u001b[0m\u001b[2m│   \u001b[0msearch_type=\u001b[33m\"\u001b[0m\u001b[33mmmr\u001b[0m\u001b[33m\"\u001b[0m,                                                         \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m   \u001b[2m160 \u001b[0m\u001b[2m│   \u001b[0msearch_kwargs={                                                            \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m \u001b[2;33m/usr/local/lib/python3.11/dist-packages/streamlit/runtime/caching/\u001b[0m\u001b[1;33mcache_utils.py\u001b[0m:\u001b[94m219\u001b[0m \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m in \u001b[92m__call__\u001b[0m                                                                          \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m \u001b[2;33m/usr/local/lib/python3.11/dist-packages/streamlit/runtime/caching/\u001b[0m\u001b[1;33mcache_utils.py\u001b[0m:\u001b[94m261\u001b[0m \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m in \u001b[92m_get_or_create_cached_value\u001b[0m                                                       \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m \u001b[2;33m/usr/local/lib/python3.11/dist-packages/streamlit/runtime/caching/\u001b[0m\u001b[1;33mcache_utils.py\u001b[0m:\u001b[94m320\u001b[0m \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m in \u001b[92m_handle_cache_miss\u001b[0m                                                                \u001b[31m \u001b[0m\n",
            "\u001b[31m────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
            "\u001b[1;91mTypeError: \u001b[0m\u001b[1;35mget_vectordb\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m missing \u001b[1;36m1\u001b[0m required positional argument: \u001b[32m'modulo'\u001b[0m\n",
            "\u001b[31m──\u001b[0m\u001b[31m────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m─────────────────────────\u001b[0m\u001b[31m──\u001b[0m\n",
            "\u001b[31m \u001b[0m \u001b[2;33m/usr/local/lib/python3.11/dist-packages/streamlit/runtime/scriptrunner/\u001b[0m\u001b[1;33mexec_code.py\u001b[0m: \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m \u001b[94m128\u001b[0m in \u001b[92mexec_func_with_error_handling\u001b[0m                                                 \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m \u001b[2;33m/usr/local/lib/python3.11/dist-packages/streamlit/runtime/scriptrunner/\u001b[0m\u001b[1;33mscript_runner\u001b[0m \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m \u001b[1;33m.py\u001b[0m:\u001b[94m669\u001b[0m in \u001b[92mcode_to_exec\u001b[0m                                                              \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m \u001b[2;33m/content/\u001b[0m\u001b[1;33mRag_answert_Poli_con_selector_modulo_visible.py\u001b[0m:\u001b[94m157\u001b[0m in \u001b[92m<module>\u001b[0m             \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m   \u001b[2m154 \u001b[0mstatus = st.empty()                                                            \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m   \u001b[2m155 \u001b[0mstatus.info(\u001b[33m\"\u001b[0m\u001b[33mCargando base vectorial y modelo de lenguaje...\u001b[0m\u001b[33m\"\u001b[0m)                 \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m   \u001b[2m156 \u001b[0m                                                                               \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m \u001b[31m❱ \u001b[0m157 vectordb = \u001b[1;4mget_vectordb()\u001b[0m                                                      \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m   \u001b[2m158 \u001b[0mretriever = vectordb.as_retriever(                                             \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m   \u001b[2m159 \u001b[0m\u001b[2m│   \u001b[0msearch_type=\u001b[33m\"\u001b[0m\u001b[33mmmr\u001b[0m\u001b[33m\"\u001b[0m,                                                         \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m   \u001b[2m160 \u001b[0m\u001b[2m│   \u001b[0msearch_kwargs={                                                            \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m \u001b[2;33m/usr/local/lib/python3.11/dist-packages/streamlit/runtime/caching/\u001b[0m\u001b[1;33mcache_utils.py\u001b[0m:\u001b[94m219\u001b[0m \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m in \u001b[92m__call__\u001b[0m                                                                          \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m \u001b[2;33m/usr/local/lib/python3.11/dist-packages/streamlit/runtime/caching/\u001b[0m\u001b[1;33mcache_utils.py\u001b[0m:\u001b[94m261\u001b[0m \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m in \u001b[92m_get_or_create_cached_value\u001b[0m                                                       \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m \u001b[2;33m/usr/local/lib/python3.11/dist-packages/streamlit/runtime/caching/\u001b[0m\u001b[1;33mcache_utils.py\u001b[0m:\u001b[94m320\u001b[0m \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m in \u001b[92m_handle_cache_miss\u001b[0m                                                                \u001b[31m \u001b[0m\n",
            "\u001b[31m────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
            "\u001b[1;91mTypeError: \u001b[0m\u001b[1;35mget_vectordb\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m missing \u001b[1;36m1\u001b[0m required positional argument: \u001b[32m'modulo'\u001b[0m\n",
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n",
            "🔄 Creando pipeline de generación de texto...\n",
            "🔄 Cargando tokenizer...\n",
            "✅ Tokenizer cargado.\n",
            "🔄 Cargando modelo...\n",
            "Loading checkpoint shards: 100% 2/2 [00:02<00:00,  1.15s/it]\n",
            "✅ Modelo cargado.\n",
            "Device set to use cuda:0\n",
            "The model 'LlamaForCausalLM' is not supported for text2text-generation. Supported models are ['PeftModelForSeq2SeqLM', 'BartForConditionalGeneration', 'BigBirdPegasusForConditionalGeneration', 'BlenderbotForConditionalGeneration', 'BlenderbotSmallForConditionalGeneration', 'EncoderDecoderModel', 'FSMTForConditionalGeneration', 'GPTSanJapaneseForConditionalGeneration', 'GraniteSpeechForConditionalGeneration', 'LEDForConditionalGeneration', 'LongT5ForConditionalGeneration', 'M2M100ForConditionalGeneration', 'MarianMTModel', 'MBartForConditionalGeneration', 'MT5ForConditionalGeneration', 'MvpForConditionalGeneration', 'NllbMoeForConditionalGeneration', 'PegasusForConditionalGeneration', 'PegasusXForConditionalGeneration', 'PLBartForConditionalGeneration', 'ProphetNetForConditionalGeneration', 'Qwen2AudioForConditionalGeneration', 'SeamlessM4TForTextToText', 'SeamlessM4Tv2ForTextToText', 'SwitchTransformersForConditionalGeneration', 'T5ForConditionalGeneration', 'T5GemmaForConditionalGeneration', 'UMT5ForConditionalGeneration', 'XLMProphetNetForConditionalGeneration'].\n",
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n",
            "🔄 Creando pipeline de generación de texto...\n",
            "🔄 Cargando tokenizer...\n",
            "✅ Tokenizer cargado.\n",
            "🔄 Cargando modelo...\n",
            "Loading checkpoint shards: 100% 2/2 [00:01<00:00,  1.05it/s]\n",
            "✅ Modelo cargado.\n",
            "Device set to use cuda:0\n",
            "The model 'LlamaForCausalLM' is not supported for text2text-generation. Supported models are ['PeftModelForSeq2SeqLM', 'BartForConditionalGeneration', 'BigBirdPegasusForConditionalGeneration', 'BlenderbotForConditionalGeneration', 'BlenderbotSmallForConditionalGeneration', 'EncoderDecoderModel', 'FSMTForConditionalGeneration', 'GPTSanJapaneseForConditionalGeneration', 'GraniteSpeechForConditionalGeneration', 'LEDForConditionalGeneration', 'LongT5ForConditionalGeneration', 'M2M100ForConditionalGeneration', 'MarianMTModel', 'MBartForConditionalGeneration', 'MT5ForConditionalGeneration', 'MvpForConditionalGeneration', 'NllbMoeForConditionalGeneration', 'PegasusForConditionalGeneration', 'PegasusXForConditionalGeneration', 'PLBartForConditionalGeneration', 'ProphetNetForConditionalGeneration', 'Qwen2AudioForConditionalGeneration', 'SeamlessM4TForTextToText', 'SeamlessM4Tv2ForTextToText', 'SwitchTransformersForConditionalGeneration', 'T5ForConditionalGeneration', 'T5GemmaForConditionalGeneration', 'UMT5ForConditionalGeneration', 'XLMProphetNetForConditionalGeneration'].\n",
            "🔄 Creando pipeline de generación de texto...\n",
            "🔄 Cargando tokenizer...\n",
            "✅ Tokenizer cargado.\n",
            "🔄 Cargando modelo...\n",
            "Loading checkpoint shards: 100% 2/2 [00:01<00:00,  1.06it/s]\n",
            "✅ Modelo cargado.\n",
            "Device set to use cuda:0\n",
            "The model 'LlamaForCausalLM' is not supported for text2text-generation. Supported models are ['PeftModelForSeq2SeqLM', 'BartForConditionalGeneration', 'BigBirdPegasusForConditionalGeneration', 'BlenderbotForConditionalGeneration', 'BlenderbotSmallForConditionalGeneration', 'EncoderDecoderModel', 'FSMTForConditionalGeneration', 'GPTSanJapaneseForConditionalGeneration', 'GraniteSpeechForConditionalGeneration', 'LEDForConditionalGeneration', 'LongT5ForConditionalGeneration', 'M2M100ForConditionalGeneration', 'MarianMTModel', 'MBartForConditionalGeneration', 'MT5ForConditionalGeneration', 'MvpForConditionalGeneration', 'NllbMoeForConditionalGeneration', 'PegasusForConditionalGeneration', 'PegasusXForConditionalGeneration', 'PLBartForConditionalGeneration', 'ProphetNetForConditionalGeneration', 'Qwen2AudioForConditionalGeneration', 'SeamlessM4TForTextToText', 'SeamlessM4Tv2ForTextToText', 'SwitchTransformersForConditionalGeneration', 'T5ForConditionalGeneration', 'T5GemmaForConditionalGeneration', 'UMT5ForConditionalGeneration', 'XLMProphetNetForConditionalGeneration'].\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionQueryEvent: capture() takes 1 positional argument but 3 were given\n",
            "🔄 Creando pipeline de generación de texto...\n",
            "🔄 Cargando tokenizer...\n",
            "✅ Tokenizer cargado.\n",
            "🔄 Cargando modelo...\n",
            "Loading checkpoint shards: 100% 2/2 [00:01<00:00,  1.03it/s]\n",
            "✅ Modelo cargado.\n",
            "Device set to use cuda:0\n",
            "The model 'LlamaForCausalLM' is not supported for text2text-generation. Supported models are ['PeftModelForSeq2SeqLM', 'BartForConditionalGeneration', 'BigBirdPegasusForConditionalGeneration', 'BlenderbotForConditionalGeneration', 'BlenderbotSmallForConditionalGeneration', 'EncoderDecoderModel', 'FSMTForConditionalGeneration', 'GPTSanJapaneseForConditionalGeneration', 'GraniteSpeechForConditionalGeneration', 'LEDForConditionalGeneration', 'LongT5ForConditionalGeneration', 'M2M100ForConditionalGeneration', 'MarianMTModel', 'MBartForConditionalGeneration', 'MT5ForConditionalGeneration', 'MvpForConditionalGeneration', 'NllbMoeForConditionalGeneration', 'PegasusForConditionalGeneration', 'PegasusXForConditionalGeneration', 'PLBartForConditionalGeneration', 'ProphetNetForConditionalGeneration', 'Qwen2AudioForConditionalGeneration', 'SeamlessM4TForTextToText', 'SeamlessM4Tv2ForTextToText', 'SwitchTransformersForConditionalGeneration', 'T5ForConditionalGeneration', 'T5GemmaForConditionalGeneration', 'UMT5ForConditionalGeneration', 'XLMProphetNetForConditionalGeneration'].\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "🔄 Creando pipeline de generación de texto...\n",
            "🔄 Cargando tokenizer...\n",
            "✅ Tokenizer cargado.\n",
            "🔄 Cargando modelo...\n",
            "Loading checkpoint shards: 100% 2/2 [00:01<00:00,  1.06it/s]\n",
            "✅ Modelo cargado.\n",
            "Device set to use cuda:0\n",
            "The model 'LlamaForCausalLM' is not supported for text2text-generation. Supported models are ['PeftModelForSeq2SeqLM', 'BartForConditionalGeneration', 'BigBirdPegasusForConditionalGeneration', 'BlenderbotForConditionalGeneration', 'BlenderbotSmallForConditionalGeneration', 'EncoderDecoderModel', 'FSMTForConditionalGeneration', 'GPTSanJapaneseForConditionalGeneration', 'GraniteSpeechForConditionalGeneration', 'LEDForConditionalGeneration', 'LongT5ForConditionalGeneration', 'M2M100ForConditionalGeneration', 'MarianMTModel', 'MBartForConditionalGeneration', 'MT5ForConditionalGeneration', 'MvpForConditionalGeneration', 'NllbMoeForConditionalGeneration', 'PegasusForConditionalGeneration', 'PegasusXForConditionalGeneration', 'PLBartForConditionalGeneration', 'ProphetNetForConditionalGeneration', 'Qwen2AudioForConditionalGeneration', 'SeamlessM4TForTextToText', 'SeamlessM4Tv2ForTextToText', 'SwitchTransformersForConditionalGeneration', 'T5ForConditionalGeneration', 'T5GemmaForConditionalGeneration', 'UMT5ForConditionalGeneration', 'XLMProphetNetForConditionalGeneration'].\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run modulo_chat_RAG.py & npx localtunnel --port 8501"
      ],
      "metadata": {
        "id": "9AtRDT_92UmZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}